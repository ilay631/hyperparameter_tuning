{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d7876e-af0d-464c-9cd1-a90fdf160055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor as LOF\n",
    "import optuna\n",
    "# For GPU version of pipeline\n",
    "import cuml\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb36b302-d597-491c-ac78-31a3974a3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_study_csv(study, filename):\n",
    "    \"\"\"\n",
    "    Write metric values and params from optuna study to csv file.\n",
    "    params:\n",
    "        study: Study - optimized optuna study\n",
    "        filename: str - where put csv file with name\n",
    "    \"\"\"\n",
    "    trials = bayesian_search_study.get_trials(deepcopy=True)\n",
    "    data = {\n",
    "        \"value\": [],\n",
    "        \"params\": []\n",
    "    }\n",
    "    for trial in trials:\n",
    "        data[\"value\"].append(trial.value)\n",
    "        data[\"params\"].append(trial.params)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename)\n",
    "\n",
    "# Чтение данных\n",
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data.drop('id', axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def load_less_data(filename, frac):\n",
    "    data = load_data(filename)\n",
    "    return data.sample(frac=frac)\n",
    "\n",
    "def find_max_value(csv_file):\n",
    "    \"\"\"\n",
    "    Finds max value from csv file where study saved.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    max_value = df['value'].max()\n",
    "    \n",
    "    return max_value\n",
    "\n",
    "def calculate_statistics(numbers):\n",
    "    \"\"\"\n",
    "    Finds median and range value for list of values.\n",
    "    \"\"\"\n",
    "    median = np.median(numbers)\n",
    "    range_value = np.ptp(numbers)\n",
    "    \n",
    "    return median, range_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc910721-8431-4d6d-9352-b567940a1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineGPU:\n",
    "    \"\"\"\n",
    "    Pipeline GPU realization: UMAP -> LOF -> HDBCAN\n",
    "    (LOF using CPU version cause there no version of LOF in RAPIDS)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        umap_n_components, umap_n_neighbors, umap_min_dist, umap_metric,\n",
    "        lof_n_neighbors, lof_metric,\n",
    "        hdb_min_cluster_size, hdb_metric, hdb_metric_params,\n",
    "        umap_precomputed_knn=None\n",
    "    ):\n",
    "        self.umap_ = cuml.UMAP(\n",
    "            n_components=umap_n_components, \n",
    "            n_neighbors=umap_n_neighbors, \n",
    "            min_dist=umap_min_dist, \n",
    "            metric=umap_metric,\n",
    "            precomputed_knn=umap_precomputed_knn\n",
    "        )\n",
    "        self.lof = LOF(\n",
    "            n_neighbors=lof_n_neighbors,\n",
    "            metric=lof_metric\n",
    "        )\n",
    "        self.hdb = cuml.HDBSCAN(\n",
    "            min_cluster_size=hdb_min_cluster_size,\n",
    "            metric=hdb_metric,\n",
    "            metric_params=hdb_metric_params\n",
    "        )\n",
    "\n",
    "    def fit_predict(self, data):\n",
    "        \"\"\"\n",
    "        Returns full reduced data and full labels for it.\n",
    "        \"\"\"\n",
    "        reduced_data = self.umap_.fit_transform(data)\n",
    "        outliers = self.lof.fit_predict(reduced_data)\n",
    "        reduced_clean_data = reduced_data[outliers == 1]\n",
    "        labels = self.hdb.fit_predict(reduced_clean_data)\n",
    "        \n",
    "        full_labels = np.full(len(reduced_data), -1)\n",
    "        full_labels[outliers == 1] = labels\n",
    "        full_labels[outliers == -1] = -2\n",
    "        return reduced_data, full_labels\n",
    "\n",
    "    def fit_predict_without_outliers(self, data):\n",
    "        \"\"\"\n",
    "        Returns clean reduced data and clean labels. All outliers deleted.\n",
    "        \"\"\"\n",
    "        reduced_data = self.umap_.fit_transform(data)\n",
    "        outliers = self.lof.fit_predict(reduced_data)\n",
    "        reduced_clean_data = reduced_data[outliers == 1]\n",
    "        labels = self.hdb.fit_predict(reduced_clean_data)\n",
    "        reduced_clean_data = reduced_clean_data[labels != -1]\n",
    "        labels = labels[labels != -1]\n",
    "        return reduced_clean_data, labels\n",
    "\n",
    "    def fit_predict_without_lof(self, data):\n",
    "        \"\"\"\n",
    "        Realization of pipeline without LOF. \n",
    "        Returns clean reduced data and clean labels. All outliers deleted.\n",
    "        \"\"\"\n",
    "        reduced_data = self.umap_.fit_transform(data)\n",
    "        labels = self.hdb.fit_predict(reduced_data)\n",
    "        reduced_clean_data = reduced_data[labels != -1]\n",
    "        labels = labels[labels != -1]\n",
    "        return reduced_clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500758b-aac1-4572-8aed-a782d272302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveGPU(trial):\n",
    "    \"\"\"\n",
    "    GPU version of objective for optuna study to optimize.\n",
    "\n",
    "    WARNING: using global_data to prevent multiply data readings\n",
    "    \"\"\"\n",
    "    global global_data\n",
    "    # Hyperparameter chooce\n",
    "    umap_n_components = trial.suggest_int(\"umap_n_components\", 2, 50)\n",
    "    umap_n_neighbors = trial.suggest_int(\"umap_n_neighbors\", 100, 2000)\n",
    "    umap_min_dist = trial.suggest_float(\"umap_min_dist\", 0.0, 0.25, step=0.01)\n",
    "    lof_n_neighbors = trial.suggest_int(\"lof_n_neighbors\", 10, 1000)\n",
    "    \n",
    "    # Pipeline creation\n",
    "    pipe = PipelineGPU(\n",
    "        umap_n_components=umap_n_components, umap_n_neighbors=umap_n_neighbors, umap_min_dist=umap_min_dist, \n",
    "        umap_metric=\"cosine\", umap_precomputed_knn=None,\n",
    "        lof_n_neighbors=lof_n_neighbors, lof_metric='minkowski', \n",
    "        hdb_min_cluster_size=500, hdb_metric='l2', hdb_metric_params=None\n",
    "    )\n",
    "\n",
    "    # Clastering with created pipeline\n",
    "    reduced_clean_data, clean_labels = pipe.fit_predict_without_outliers(global_data)\n",
    "    \n",
    "    # Get silhouette score for clasterisation\n",
    "    if len(np.unique(clean_labels)) > 1:\n",
    "        score = cuml.metrics.cluster.silhouette_score(reduced_clean_data, clean_labels)\n",
    "        return score\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065ac3a-50d0-45da-870d-b1517f59f626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Bayesian search (Most efficient)\n",
    "global_data = load_data(\"photos_clip.csv\")\n",
    "n_trials = 100\n",
    "filename = f\"bayesian_study.csv\"\n",
    "\n",
    "bayesian_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "bayesian_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "\n",
    "write_study_csv(bayesian_search_study, filename)\n",
    "\n",
    "print(f\"Best found metric value = {bayesian_search_study.best_value}\")\n",
    "print(f\"Best found params: {bayesian_search_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ba84f-ebb0-485d-92f8-d82c50a29c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random search\n",
    "global_data = load_data(\"photos_clip.csv\")\n",
    "n_trials = 100\n",
    "filename = f\"random_study.csv\"\n",
    "\n",
    "random_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler())\n",
    "random_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "\n",
    "write_study_csv(random_search_study, filename)\n",
    "\n",
    "print(f\"Best found metric value = {random_search_study.best_value}\")\n",
    "print(f\"Best found params: {random_search_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16137fd-c98a-49f9-b210-aea5d7a09deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evolution search\n",
    "global_data = load_data(\"photos_clip.csv\")\n",
    "n_trials = 100\n",
    "filename = f\"evolution_study.csv\"\n",
    "\n",
    "evolution_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "evolution_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "\n",
    "write_study_csv(evolution_search_study, filename)\n",
    "\n",
    "print(f\"Best found metric value = {evolution_search_study.best_value}\")\n",
    "print(f\"Best found params: {evolution_search_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ece299-8350-41d9-a35f-f1bba497adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid Search\n",
    "\n",
    "global_data = load_data(\"photos_clip.csv\")\n",
    "n_trials = 100\n",
    "filename = f\"grid_study.csv\"\n",
    "\n",
    "search_space = {\n",
    "    \"umap_n_components\": [2, 5, 10, 15, 20, 35, 50],\n",
    "    \"umap_n_neighbors\": [100, 250, 500, 1000, 1500, 2000],\n",
    "    \"umap_min_dist\": [0.0, 0.025, 0.1, 0.25],\n",
    "    \"lof_n_neighbors\": [10, 100, 250, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.GridSampler(search_space))\n",
    "grid_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "\n",
    "write_study_csv(grid_search_study, filename)\n",
    "\n",
    "print(f\"Best found metric value = {grid_search_study.best_value}\")\n",
    "print(f\"Best found params: {grid_search_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445a626-816e-4707-827a-033371d4f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "global_data = load_data(\"photos_clip.csv\")\n",
    "n_trials = 100\n",
    "study_count = 10\n",
    "\n",
    "for i in range(study_count):\n",
    "    # Evolutionary\n",
    "    filename = f\"evolution_study_{i}.csv\"\n",
    "    evolution_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "    evolution_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "    write_study_csv(evolution_search_study, filename)\n",
    "\n",
    "    # Random\n",
    "    filename = f\"random_study_{i}.csv\"\n",
    "    random_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler())\n",
    "    random_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "    write_study_csv(random_search_study, filename)\n",
    "\n",
    "    # Bayesian\n",
    "    filename = f\"bayesian_study_{i}.csv\"\n",
    "    bayesian_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "    bayesian_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "    write_study_csv(bayesian_search_study, filename)\n",
    "\n",
    "# Grid\n",
    "search_space = {\n",
    "    \"umap_n_components\": [2, 5, 10, 15, 20, 35, 50],\n",
    "    \"umap_n_neighbors\": [100, 250, 500, 1000, 1500, 2000],\n",
    "    \"umap_min_dist\": [0.0, 0.025, 0.1, 0.25],\n",
    "    \"lof_n_neighbors\": [10, 100, 250, 500, 1000]\n",
    "}\n",
    "\n",
    "filename = f\"grid_study.csv\"\n",
    "grid_search_study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.GridSampler(search_space))\n",
    "grid_search_study.optimize(objectiveGPU, n_trials=n_trials, n_jobs=1, show_progress_bar=True, catch=[Exception])\n",
    "write_study_csv(grid_search_study, filename)\n",
    "\n",
    "# Get results\n",
    "print(f\"Grid: {find_max_value(\"grid_study.csv\")}\")\n",
    "print(f\"Random: {calculate_statistics([find_max_value(f\"random_study_{i}.csv\") for i in range(study_count)])}\")\n",
    "print(f\"Bayesian: {calculate_statistics([find_max_value(f\"bayesian_study_{i}.csv\") for i in range(study_count)])}\")\n",
    "print(f\"Evolutionary: {calculate_statistics([find_max_value(f\"evolution_study_{i}.csv\") for i in range(study_count)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc45925-1f04-4a0a-bce3-b338c5d0dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def find_top_n_values_in_csv(n):\n",
    "    csv_files = glob.glob(\"**/*study*.csv\", recursive=True)\n",
    "    all_data = pd.DataFrame()\n",
    "    for file in csv_files:\n",
    "        data = pd.read_csv(file)\n",
    "        all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "    \n",
    "    top_n_values = all_data.nlargest(n, 'value')\n",
    "    top_n_params = top_n_values[['value', 'params']]\n",
    "    return top_n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8f117-8174-470b-8072-69b21909ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "import time\n",
    "\n",
    "data = load_data(\"photos_clip.csv\")\n",
    "\n",
    "params = find_top_n_values_in_csv(10)\n",
    "\n",
    "for i, row in params.iterrows():\n",
    "    p = eval(row[\"params\"])\n",
    "    umap_n_components = p[\"umap_n_components\"]\n",
    "    umap_n_neighbors = p[\"umap_n_neighbors\"]\n",
    "    umap_min_dist = p[\"umap_min_dist\"]\n",
    "    lof_n_neighbors = p[\"lof_n_neighbors\"]\n",
    "    \n",
    "    pipe = PipelineGPU(\n",
    "        umap_n_components=umap_n_components, umap_n_neighbors=umap_n_neighbors, umap_min_dist=umap_min_dist, \n",
    "        umap_metric=\"cosine\", umap_precomputed_knn=None,\n",
    "        lof_n_neighbors=lof_n_neighbors, lof_metric='minkowski', \n",
    "        hdb_min_cluster_size=500, hdb_metric='l2', hdb_metric_params=None\n",
    "    )\n",
    "\n",
    "    start_time_with_lof = time.perf_counter()\n",
    "    reduced_clean_data1, clean_labels1 = pipe.fit_predict_without_outliers(data)\n",
    "    end_time_with_lof = time.perf_counter()\n",
    "\n",
    "    start_time_without_lof = time.perf_counter()\n",
    "    reduced_clean_data2, clean_labels2 = pipe.fit_predict_without_lof(data)\n",
    "    end_time_without_lof = time.perf_counter()\n",
    "\n",
    "    print(i, end_time_with_lof - start_time_with_lof, end_time_without_lof - start_time_without_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72a5a2-14a1-41b3-8e0b-70a577ac651d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
